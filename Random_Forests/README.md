# Random Forests on Random Forests

Continuation of [Forest Cover Type Analysis](https://github.com/adamszabunio/Forest_Cover_Type/tree/master/EDA/)

From [One-VS-Rest Logistic Regression](https://github.com/adamszabunio/Forest_Cover_Type/tree/master/EDA/Further_EDA_and_Logistic_Regression.ipynb) I learned the importance of model selection as well as feature scaling. 

In this set of notebooks, I explore the power and simplicity of the popular [scikit-learn](http://scikit-learn.org/stable/) Machine Learning API in Python. 

During the second semester of my M.S. Data Science Program, one of our Machine Learning Practicums included an Object Oriented Programing implementation of [Random Forests](random_forests.py) 

A notebook exploring this algorithm on the [Forest Cover Type Kaggle Dataset](https://www.kaggle.com/uciml/forest-cover-type-dataset) alongside the scikit-learn version can be found [here](Random_Forests_on_Random_Forests.ipynb)

![](images/algo_time_score_comparison.png?raw=true)

Furthermore, I begin to explore the speed and accuracy of [boosting algorithims](ada_boost_vs_random_forests.ipynb)

[Continued Analysis of Boosting Algorithims and Feature Importances via Natural Language Processing (NLP)](https://github.com/adamszabunio/Forest_Cover_Type/tree/master/NLP)

